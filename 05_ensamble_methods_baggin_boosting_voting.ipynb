{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3701773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "data_breast_cancer = datasets.load_breast_cancer(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "598f3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data_breast_cancer.data[['mean texture', 'mean symmetry']]\n",
    "y = data_breast_cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b121d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "clf_lr = LogisticRegression()\n",
    "clf_knn = KNeighborsClassifier()\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensamble_hard = VotingClassifier(estimators=[\n",
    "    ('dt', clf_dt),\n",
    "    ('lr', clf_lr),\n",
    "    ('knn', clf_knn)\n",
    "], voting='hard')\n",
    "\n",
    "ensaable_soft = VotingClassifier(estimators=[\n",
    "    ('dt', clf_dt),\n",
    "    ('lr', clf_lr),\n",
    "    ('knn', clf_knn)\n",
    "], voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c827faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_acc = clf.score(X_train, y_train)\n",
    "    test_acc = clf.score(X_test, y_test)\n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e3be4646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 0.6929824561403509), (0.6901098901098901, 0.7543859649122807), (0.7582417582417582, 0.7192982456140351), (0.843956043956044, 0.7368421052631579), (0.9692307692307692, 0.7280701754385965)]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "vote = []\n",
    "for model in [clf_dt, clf_lr, clf_knn, ensamble_hard, ensaable_soft]:\n",
    "    train_acc, test_acc = train_and_evaluate(model, X_train, y_train, X_test, y_test)\n",
    "    results.append((train_acc, test_acc))\n",
    "    vote.append(model)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "95238034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zapis wynikow w picklu\n",
    "import pickle\n",
    "with open('acc_vote.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "with open('vote.pkl', 'wb') as f:\n",
    "    pickle.dump(vote, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "464be986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 decision trees\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "\n",
    "base_tree = DecisionTreeClassifier()\n",
    "\n",
    "models = [\n",
    "    BaggingClassifier(estimator=base_tree, n_estimators=30, bootstrap=True), \n",
    "    BaggingClassifier(estimator=base_tree, n_estimators=30, bootstrap=True, max_samples=0.5),\n",
    "    BaggingClassifier(estimator=base_tree, n_estimators=30, bootstrap=False),\n",
    "    BaggingClassifier(estimator=base_tree, n_estimators=30, bootstrap=False, max_samples=0.5), \n",
    "    RandomForestClassifier(n_estimators=30),\n",
    "    AdaBoostClassifier(estimator=base_tree, n_estimators=30), \n",
    "    GradientBoostingClassifier(n_estimators=30) \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 0.7105263157894737), (0.9164835164835164, 0.7017543859649122), (1.0, 0.7017543859649122), (0.9604395604395605, 0.7105263157894737), (0.9978021978021978, 0.6842105263157895), (1.0, 0.7017543859649122), (0.7956043956043956, 0.7631578947368421)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igorw\\miniforge3\\envs\\ml\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate models\n",
    "bag_results = []\n",
    "bag_classifiers = []\n",
    "\n",
    "for model in models:\n",
    "    train_acc, test_acc = train_and_evaluate(model, X_train, y_train, X_test, y_test)\n",
    "    bag_results.append((train_acc, test_acc))\n",
    "    bag_classifiers.append(model)\n",
    "\n",
    "print(bag_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98cb44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "with open('acc_bag.pkl', 'wb') as f:\n",
    "    pickle.dump(bag_results, f)\n",
    "\n",
    "with open('bag.pkl', 'wb') as f:\n",
    "    pickle.dump(bag_classifiers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1004b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 sampling with replacement\n",
    "X = data_breast_cancer.data\n",
    "y = data_breast_cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "fea_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=30,\n",
    "    bootstrap=True,\n",
    "    max_samples=0.5,\n",
    "    bootstrap_features=False,\n",
    "    max_features=2\n",
    ")\n",
    "\n",
    "train_acc, test_acc = train_and_evaluate(fea_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "with open('acc_fea.pkl', 'wb') as f:\n",
    "    pickle.dump([(train_acc, test_acc)], f)\n",
    "\n",
    "with open('fea.pkl', 'wb') as f:\n",
    "    pickle.dump([fea_model], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e6c915a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    train_accuracy  test_accuracy  \\\n",
      "0         0.802198       0.587719   \n",
      "1         0.758242       0.631579   \n",
      "2         0.839560       0.719298   \n",
      "3         0.760440       0.675439   \n",
      "4         0.749451       0.605263   \n",
      "5         0.927473       0.947368   \n",
      "6         0.898901       0.833333   \n",
      "7         0.810989       0.666667   \n",
      "8         0.815385       0.736842   \n",
      "9         0.813187       0.657895   \n",
      "10        0.835165       0.789474   \n",
      "11        0.819780       0.789474   \n",
      "12        0.945055       0.894737   \n",
      "13        0.931868       0.912281   \n",
      "14        0.749451       0.614035   \n",
      "15        0.745055       0.614035   \n",
      "16        0.736264       0.508772   \n",
      "17        0.907692       0.903509   \n",
      "18        0.907692       0.956140   \n",
      "19        0.857143       0.763158   \n",
      "20        0.756044       0.605263   \n",
      "21        0.885714       0.859649   \n",
      "22        0.918681       0.885965   \n",
      "23        0.912088       0.885965   \n",
      "24        0.887912       0.868421   \n",
      "25        0.914286       0.868421   \n",
      "26        0.936264       0.885965   \n",
      "27        0.927473       0.912281   \n",
      "28        0.918681       0.868421   \n",
      "29        0.795604       0.649123   \n",
      "\n",
      "                                  selected_features  \n",
      "0                 [smoothness error, worst texture]  \n",
      "1       [fractal dimension error, worst smoothness]  \n",
      "2              [concave points error, mean texture]  \n",
      "3       [compactness error, mean fractal dimension]  \n",
      "4          [fractal dimension error, mean symmetry]  \n",
      "5                       [mean concavity, mean area]  \n",
      "6                [smoothness error, mean perimeter]  \n",
      "7                     [texture error, mean texture]  \n",
      "8                [symmetry error, mean compactness]  \n",
      "9            [concave points error, symmetry error]  \n",
      "10                [worst compactness, mean texture]  \n",
      "11              [worst smoothness, concavity error]  \n",
      "12                    [mean area, worst smoothness]  \n",
      "13                [mean smoothness, mean perimeter]  \n",
      "14  [fractal dimension error, concave points error]  \n",
      "15            [smoothness error, compactness error]  \n",
      "16                  [symmetry error, texture error]  \n",
      "17              [mean radius, concave points error]  \n",
      "18          [worst concave points, worst concavity]  \n",
      "19               [mean smoothness, perimeter error]  \n",
      "20               [texture error, compactness error]  \n",
      "21              [mean radius, concave points error]  \n",
      "22                     [mean symmetry, mean radius]  \n",
      "23                  [mean symmetry, mean perimeter]  \n",
      "24                         [mean area, mean radius]  \n",
      "25          [worst concave points, mean smoothness]  \n",
      "26                 [worst texture, worst perimeter]  \n",
      "27                    [area error, worst perimeter]  \n",
      "28      [concave points error, mean concave points]  \n",
      "29              [compactness error, symmetry error]  \n"
     ]
    }
   ],
   "source": [
    "# 9 feature ranking\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "estimators = fea_model.estimators_\n",
    "features_per_estimator = fea_model.estimators_features_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "\n",
    "# Compute accuracies for each estimator\n",
    "results = []\n",
    "for i, (estimator, feat_indices) in enumerate(zip(estimators, features_per_estimator)):\n",
    "    # Get the selected feature names\n",
    "    selected_features = list(feature_names[feat_indices])\n",
    "    \n",
    "    # Predict on train and test sets (using only selected features)\n",
    "    X_train_subset = X_train.iloc[:, feat_indices].values\n",
    "    X_test_subset = X_test.iloc[:, feat_indices].values\n",
    "    \n",
    "    y_train_pred = estimator.predict(X_train_subset)\n",
    "    y_test_pred = estimator.predict(X_test_subset)\n",
    "    \n",
    "    # Compute accuracies\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'selected_features': selected_features\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "df_ranking = pd.DataFrame(results)\n",
    "print(df_ranking)\n",
    "\n",
    "df_ranking = df_ranking.sort_values(\n",
    "    by=['test_accuracy', 'train_accuracy'],\n",
    "    ascending=False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
